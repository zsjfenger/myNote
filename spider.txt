1、爬虫的基本原理

	 网络爬虫是人饕擎抓取系统的重要组成部分。爬虫的主要目的是将互联网上的网页下载到本地形成一个或联网内容的镜像备份

2、基本工作流程
	1.首先选取一部分精心挑选的种子URL；

    	2.将这些URL放入待抓取URL队列；

    	3.从待抓取URL队列中取出待抓取在URL，解析DNS，并且得到主机的ip，并将URL对应的网页下载下来，存储进已下载网页库中。此外，将这些URL放进已抓取URL队列。
	
    	4.分析已抓取URL队列中的URL，分析其中的其他URL，并且将URL放入待抓取URL队列，从而进入下一个循环。
3、正则表达式
	Python   引用模块   re
	re.search(r'FishC', 'I love FishC.com!') # search() 方法用于在字符串搜索正则表达式模式第一次出现的位置
	re.search(r'.', 'I love FishC.com!')	# . 匹配任意字符，除了换行符
	re.search(r'\.', 'I love FishC.com!')	# 匹配 . ,特殊字符匹配在之前加上\
        \d 匹配数字
	匹配数字0-255 ：re.search(r'[01]\d\d|2[0-4]\d|25[0-5]', '188')   
	
	匹配IP： re.search(r'(([01]{0,1}\d{0,1}\d|2[0-4]\d|25[0-5])\.){3}([01]{0,1}\d{0,1}\d|2[0-4]\d|25[0-5])', '192.168.1.1')
	re.findall(r"[a-z]", "FishC.com") #把所有匹配的字符打包成列表显示出来
        正则表达式注意不要有空格


	如果你需要重复地使用某个正则表达式，那么你可以先将该正则表达式编译成模式对象。我们使用re.compile()方法编译......
	p = re.compile(r"[A-Z]")
	p.search("I love FishC.com!")
	p.findall("I love FishC.com!")